{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2cee18-e06c-4541-88f9-2d5bca2b19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea076d9-42b7-4878-9c12-99a5b6cf58da",
   "metadata": {},
   "source": [
    "## Part(a) \n",
    "#### Use the load_breast_cancer() function from sklearn.datasets to load the breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24322829-e410-41d6-af37-8fa7c4e385a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data is:  (569, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"The shape of the data is: \", data.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c9fb0-5431-47ba-bf82-c3d9fcef28ab",
   "metadata": {},
   "source": [
    "## Part(b) \n",
    "#### Convert the dataset into a pandas DataFrame using the pd.DataFrame() function. Make sure to specify columns= to display the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d29ddb09-15f7-4770-92a5-e698476eb068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean concavity for observation 564:  0.3174\n",
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "# Convert the dataset into a pandas DataFrame\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Get the mean concavity for observation 564\n",
    "mean_concavity_564 = df.loc[563, \"mean concavity\"]\n",
    "print(\"The mean concavity for observation 564: \", mean_concavity_564)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07c0a26-72ad-480c-8b72-db5ad1cf1bd1",
   "metadata": {},
   "source": [
    "## Part(c) \n",
    "#### Split the data into three sets: training, validation, and test sets. Use an 80-10-10 split. Use train_test_split() with the test_size parameter to first split the data into 80% training and 20% temporary data. Then split the temporary data again into 50% validation and 50% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066fb933-1ada-46f3-810f-958252ff24db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (455, 30)\n",
      "Validation data shape: (57, 30)\n",
      "Test data shape: (57, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into 80% training and 20% temporary data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary data into 50% validation and 50% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the shapes of the three datasets\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd25bc-e115-4fcb-a258-9adcd649966a",
   "metadata": {},
   "source": [
    "## Part(d)\n",
    "#### Standardize the training, validation, and test datasets using StandardScaler. Fit the scaler on the training data and transform the training dataset using fit_transform. Apply transform to both validation and test dataset using the same scaler fitted on the training data.ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50178a6e-7eaf-4716-882a-5901b75fd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler and apply transformation on trianing, validation and test dataset\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd019f-9cce-47c2-bd6f-9b442501b3b9",
   "metadata": {},
   "source": [
    "## Part(e)\n",
    "#### Create a feedforward neural network (FNN) using tensorflow.keras (or keras): The network should include one hidden layer with 16 neurons and ReLU activation and an output layer with 1 neuron and Sigmoid activation for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e718c20e-0cf5-43b2-9737-dde80bf38369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valha\\anaconda3\\envs\\stat_479\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Build the Model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(16, input_shape=(30,), activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6029990-5fc6-4f38-92cb-8e36c5b4321e",
   "metadata": {},
   "source": [
    "## Part(f)\n",
    "#### Compile the model using binary_crossentropy loss function, Adam optimizer, and tTrack accuracy during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb02a089-a1ea-4965-9a30-4797caebe103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m513\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m513\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f5505-4301-4c72-8f6e-c509ec75fc9d",
   "metadata": {},
   "source": [
    "## Part (g)\n",
    "#### Train the model for 100 epochs, but include the validation data during training by passing the validation_data argument to model.fit(). Use the training data for training and validation data for monitoring overfitting. Record the loss and accuracy for both training and validation data at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf489d03-3ad0-4030-8b19-91ac07671a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3595 - loss: 0.8481 - val_accuracy: 0.7544 - val_loss: 0.5721\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6919 - loss: 0.5942 - val_accuracy: 0.8246 - val_loss: 0.4414\n",
      "Epoch 3/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8007 - loss: 0.4884 - val_accuracy: 0.8421 - val_loss: 0.3607\n",
      "Epoch 4/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.3771 - val_accuracy: 0.8947 - val_loss: 0.3038\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.3185 - val_accuracy: 0.9123 - val_loss: 0.2627\n",
      "Epoch 6/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.2865 - val_accuracy: 0.9123 - val_loss: 0.2330\n",
      "Epoch 7/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2445 - val_accuracy: 0.9123 - val_loss: 0.2090\n",
      "Epoch 8/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.2093 - val_accuracy: 0.9123 - val_loss: 0.1895\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.2223 - val_accuracy: 0.9298 - val_loss: 0.1743\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.1791 - val_accuracy: 0.9298 - val_loss: 0.1611\n",
      "Epoch 11/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9324 - loss: 0.1854 - val_accuracy: 0.9298 - val_loss: 0.1515\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.1672 - val_accuracy: 0.9298 - val_loss: 0.1422\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.1758 - val_accuracy: 0.9298 - val_loss: 0.1347\n",
      "Epoch 14/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1498 - val_accuracy: 0.9474 - val_loss: 0.1286\n",
      "Epoch 15/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.1153 - val_accuracy: 0.9474 - val_loss: 0.1232\n",
      "Epoch 16/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9635 - loss: 0.1268 - val_accuracy: 0.9474 - val_loss: 0.1186\n",
      "Epoch 17/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9654 - loss: 0.1264 - val_accuracy: 0.9474 - val_loss: 0.1147\n",
      "Epoch 18/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.1104 - val_accuracy: 0.9474 - val_loss: 0.1112\n",
      "Epoch 19/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9786 - loss: 0.0956 - val_accuracy: 0.9474 - val_loss: 0.1085\n",
      "Epoch 20/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.1219 - val_accuracy: 0.9474 - val_loss: 0.1059\n",
      "Epoch 21/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9748 - loss: 0.1121 - val_accuracy: 0.9474 - val_loss: 0.1035\n",
      "Epoch 22/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0920 - val_accuracy: 0.9474 - val_loss: 0.1016\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0775 - val_accuracy: 0.9474 - val_loss: 0.0996\n",
      "Epoch 24/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9749 - loss: 0.1016 - val_accuracy: 0.9649 - val_loss: 0.0981\n",
      "Epoch 25/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0915 - val_accuracy: 0.9649 - val_loss: 0.0966\n",
      "Epoch 26/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0897 - val_accuracy: 0.9649 - val_loss: 0.0952\n",
      "Epoch 27/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9774 - loss: 0.0883 - val_accuracy: 0.9649 - val_loss: 0.0938\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0823 - val_accuracy: 0.9649 - val_loss: 0.0922\n",
      "Epoch 29/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0771 - val_accuracy: 0.9649 - val_loss: 0.0913\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0698 - val_accuracy: 0.9649 - val_loss: 0.0907\n",
      "Epoch 31/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.0922 - val_accuracy: 0.9649 - val_loss: 0.0899\n",
      "Epoch 32/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0663 - val_accuracy: 0.9649 - val_loss: 0.0891\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9799 - loss: 0.0773 - val_accuracy: 0.9649 - val_loss: 0.0880\n",
      "Epoch 34/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0678 - val_accuracy: 0.9649 - val_loss: 0.0870\n",
      "Epoch 35/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.0574 - val_accuracy: 0.9649 - val_loss: 0.0861\n",
      "Epoch 36/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9809 - loss: 0.0654 - val_accuracy: 0.9649 - val_loss: 0.0850\n",
      "Epoch 37/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.0664 - val_accuracy: 0.9649 - val_loss: 0.0848\n",
      "Epoch 38/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0621 - val_accuracy: 0.9649 - val_loss: 0.0850\n",
      "Epoch 39/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0744 - val_accuracy: 0.9649 - val_loss: 0.0845\n",
      "Epoch 40/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.0629 - val_accuracy: 0.9649 - val_loss: 0.0839\n",
      "Epoch 41/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9878 - loss: 0.0544 - val_accuracy: 0.9649 - val_loss: 0.0837\n",
      "Epoch 42/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0647 - val_accuracy: 0.9649 - val_loss: 0.0826\n",
      "Epoch 43/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0421 - val_accuracy: 0.9825 - val_loss: 0.0822\n",
      "Epoch 44/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0708 - val_accuracy: 0.9825 - val_loss: 0.0816\n",
      "Epoch 45/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.0582 - val_accuracy: 0.9825 - val_loss: 0.0817\n",
      "Epoch 46/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0562 - val_accuracy: 0.9825 - val_loss: 0.0816\n",
      "Epoch 47/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0618 - val_accuracy: 0.9649 - val_loss: 0.0817\n",
      "Epoch 48/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0668 - val_accuracy: 0.9649 - val_loss: 0.0815\n",
      "Epoch 49/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0531 - val_accuracy: 0.9649 - val_loss: 0.0811\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0532 - val_accuracy: 0.9649 - val_loss: 0.0806\n",
      "Epoch 51/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.0567 - val_accuracy: 0.9649 - val_loss: 0.0802\n",
      "Epoch 52/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0449 - val_accuracy: 0.9649 - val_loss: 0.0802\n",
      "Epoch 53/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9806 - loss: 0.0562 - val_accuracy: 0.9649 - val_loss: 0.0805\n",
      "Epoch 54/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0487 - val_accuracy: 0.9649 - val_loss: 0.0803\n",
      "Epoch 55/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0630 - val_accuracy: 0.9649 - val_loss: 0.0807\n",
      "Epoch 56/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0505 - val_accuracy: 0.9649 - val_loss: 0.0806\n",
      "Epoch 57/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0446 - val_accuracy: 0.9649 - val_loss: 0.0801\n",
      "Epoch 58/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0526 - val_accuracy: 0.9649 - val_loss: 0.0802\n",
      "Epoch 59/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0532 - val_accuracy: 0.9649 - val_loss: 0.0802\n",
      "Epoch 60/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9885 - loss: 0.0426 - val_accuracy: 0.9649 - val_loss: 0.0791\n",
      "Epoch 61/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9805 - loss: 0.0579 - val_accuracy: 0.9649 - val_loss: 0.0785\n",
      "Epoch 62/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0535 - val_accuracy: 0.9649 - val_loss: 0.0788\n",
      "Epoch 63/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0377 - val_accuracy: 0.9649 - val_loss: 0.0789\n",
      "Epoch 64/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0450 - val_accuracy: 0.9649 - val_loss: 0.0791\n",
      "Epoch 65/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0361 - val_accuracy: 0.9649 - val_loss: 0.0795\n",
      "Epoch 66/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0357 - val_accuracy: 0.9649 - val_loss: 0.0794\n",
      "Epoch 67/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0429 - val_accuracy: 0.9649 - val_loss: 0.0798\n",
      "Epoch 68/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0548 - val_accuracy: 0.9649 - val_loss: 0.0798\n",
      "Epoch 69/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9880 - loss: 0.0402 - val_accuracy: 0.9649 - val_loss: 0.0796\n",
      "Epoch 70/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0433 - val_accuracy: 0.9649 - val_loss: 0.0790\n",
      "Epoch 71/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0522 - val_accuracy: 0.9649 - val_loss: 0.0791\n",
      "Epoch 72/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0573 - val_accuracy: 0.9649 - val_loss: 0.0791\n",
      "Epoch 73/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0360 - val_accuracy: 0.9649 - val_loss: 0.0794\n",
      "Epoch 74/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0300 - val_accuracy: 0.9649 - val_loss: 0.0797\n",
      "Epoch 75/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0301 - val_accuracy: 0.9649 - val_loss: 0.0795\n",
      "Epoch 76/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0322 - val_accuracy: 0.9649 - val_loss: 0.0798\n",
      "Epoch 77/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9797 - loss: 0.0624 - val_accuracy: 0.9649 - val_loss: 0.0798\n",
      "Epoch 78/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0517 - val_accuracy: 0.9649 - val_loss: 0.0795\n",
      "Epoch 79/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0359 - val_accuracy: 0.9649 - val_loss: 0.0794\n",
      "Epoch 80/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0308 - val_accuracy: 0.9649 - val_loss: 0.0801\n",
      "Epoch 81/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0300 - val_accuracy: 0.9649 - val_loss: 0.0803\n",
      "Epoch 82/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0359 - val_accuracy: 0.9649 - val_loss: 0.0801\n",
      "Epoch 83/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0288 - val_accuracy: 0.9649 - val_loss: 0.0799\n",
      "Epoch 84/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0286 - val_accuracy: 0.9649 - val_loss: 0.0803\n",
      "Epoch 85/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0391 - val_accuracy: 0.9649 - val_loss: 0.0808\n",
      "Epoch 86/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0412 - val_accuracy: 0.9649 - val_loss: 0.0801\n",
      "Epoch 87/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0293 - val_accuracy: 0.9649 - val_loss: 0.0800\n",
      "Epoch 88/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0285 - val_accuracy: 0.9649 - val_loss: 0.0802\n",
      "Epoch 89/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0342 - val_accuracy: 0.9649 - val_loss: 0.0811\n",
      "Epoch 90/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0323 - val_accuracy: 0.9649 - val_loss: 0.0808\n",
      "Epoch 91/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0353 - val_accuracy: 0.9649 - val_loss: 0.0804\n",
      "Epoch 92/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0301 - val_accuracy: 0.9649 - val_loss: 0.0809\n",
      "Epoch 93/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9948 - loss: 0.0283 - val_accuracy: 0.9649 - val_loss: 0.0808\n",
      "Epoch 94/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0277 - val_accuracy: 0.9649 - val_loss: 0.0808\n",
      "Epoch 95/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9892 - loss: 0.0316 - val_accuracy: 0.9649 - val_loss: 0.0803\n",
      "Epoch 96/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.0252 - val_accuracy: 0.9649 - val_loss: 0.0804\n",
      "Epoch 97/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0283 - val_accuracy: 0.9649 - val_loss: 0.0813\n",
      "Epoch 98/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0451 - val_accuracy: 0.9649 - val_loss: 0.0822\n",
      "Epoch 99/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0370 - val_accuracy: 0.9649 - val_loss: 0.0819\n",
      "Epoch 100/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0343 - val_accuracy: 0.9649 - val_loss: 0.0820\n",
      "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])\n",
      "Validation Accuracy after 100 epochs: 0.9649\n"
     ]
    }
   ],
   "source": [
    "# Train the model for 100 epochs with validation data\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=100, \n",
    "    validation_data=(X_val_scaled, y_val)\n",
    ")\n",
    "\n",
    "# Retrieve the recorded history for loss and accuracy\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "# Get the validation accuracy after 100 epochs\n",
    "val_accuracy = history.history['val_accuracy'][-1]\n",
    "print(\"Validation Accuracy after 100 epochs: {:.4f}\".format(val_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d07e45d-d06d-44ae-bcb2-b13e3f6e6083",
   "metadata": {},
   "source": [
    "## Part(h)\n",
    "\n",
    "#### After training, plot the training loss and validation loss over the 100 epochs, and use this plot to visually determine the point at which the model begins to overfitt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "411e4209-7574-4b62-9e01-1b55eae22370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be84f11-672e-4d20-8119-b8204f8d8340",
   "metadata": {},
   "source": [
    "### The optimal epochs is 70, because at epoch 70 the validation curves starts to increase. Besides, the model starts to overfit after 56 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7815075-4108-4806-93d3-79becd33b9a9",
   "metadata": {},
   "source": [
    "## Part (i) According to (h), rebuild your FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01c2bde4-8832-4caa-b8be-a52a098a1cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2057 - loss: 1.3276 - val_accuracy: 0.5088 - val_loss: 0.7943\n",
      "Epoch 2/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3904 - loss: 0.9106 - val_accuracy: 0.7193 - val_loss: 0.5696\n",
      "Epoch 3/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6666 - loss: 0.6480 - val_accuracy: 0.9123 - val_loss: 0.4272\n",
      "Epoch 4/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.4826 - val_accuracy: 0.9123 - val_loss: 0.3434\n",
      "Epoch 5/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.3513 - val_accuracy: 0.9123 - val_loss: 0.2926\n",
      "Epoch 6/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.2867 - val_accuracy: 0.9123 - val_loss: 0.2574\n",
      "Epoch 7/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9240 - loss: 0.2771 - val_accuracy: 0.9123 - val_loss: 0.2314\n",
      "Epoch 8/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9317 - loss: 0.2361 - val_accuracy: 0.9298 - val_loss: 0.2117\n",
      "Epoch 9/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9238 - loss: 0.2234 - val_accuracy: 0.9298 - val_loss: 0.1956\n",
      "Epoch 10/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9501 - loss: 0.2017 - val_accuracy: 0.9298 - val_loss: 0.1831\n",
      "Epoch 11/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9745 - loss: 0.1622 - val_accuracy: 0.9298 - val_loss: 0.1732\n",
      "Epoch 12/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9515 - loss: 0.1913 - val_accuracy: 0.9298 - val_loss: 0.1649\n",
      "Epoch 13/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9491 - loss: 0.1673 - val_accuracy: 0.9298 - val_loss: 0.1577\n",
      "Epoch 14/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.1731 - val_accuracy: 0.9298 - val_loss: 0.1516\n",
      "Epoch 15/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.1423 - val_accuracy: 0.9298 - val_loss: 0.1462\n",
      "Epoch 16/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9714 - loss: 0.1341 - val_accuracy: 0.9298 - val_loss: 0.1416\n",
      "Epoch 17/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.1338 - val_accuracy: 0.9298 - val_loss: 0.1377\n",
      "Epoch 18/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.1249 - val_accuracy: 0.9298 - val_loss: 0.1337\n",
      "Epoch 19/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9616 - loss: 0.1473 - val_accuracy: 0.9298 - val_loss: 0.1302\n",
      "Epoch 20/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.1212 - val_accuracy: 0.9298 - val_loss: 0.1273\n",
      "Epoch 21/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.1131 - val_accuracy: 0.9298 - val_loss: 0.1247\n",
      "Epoch 22/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9611 - loss: 0.1241 - val_accuracy: 0.9298 - val_loss: 0.1220\n",
      "Epoch 23/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.1025 - val_accuracy: 0.9474 - val_loss: 0.1199\n",
      "Epoch 24/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.1021 - val_accuracy: 0.9474 - val_loss: 0.1183\n",
      "Epoch 25/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0959 - val_accuracy: 0.9474 - val_loss: 0.1166\n",
      "Epoch 26/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9771 - loss: 0.0964 - val_accuracy: 0.9474 - val_loss: 0.1148\n",
      "Epoch 27/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9778 - loss: 0.0940 - val_accuracy: 0.9474 - val_loss: 0.1132\n",
      "Epoch 28/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9760 - loss: 0.0943 - val_accuracy: 0.9474 - val_loss: 0.1117\n",
      "Epoch 29/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9811 - loss: 0.0781 - val_accuracy: 0.9474 - val_loss: 0.1104\n",
      "Epoch 30/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9748 - loss: 0.0952 - val_accuracy: 0.9474 - val_loss: 0.1091\n",
      "Epoch 31/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9747 - loss: 0.0897 - val_accuracy: 0.9474 - val_loss: 0.1080\n",
      "Epoch 32/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 0.0902 - val_accuracy: 0.9474 - val_loss: 0.1069\n",
      "Epoch 33/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0907 - val_accuracy: 0.9474 - val_loss: 0.1057\n",
      "Epoch 34/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.0783 - val_accuracy: 0.9474 - val_loss: 0.1049\n",
      "Epoch 35/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0747 - val_accuracy: 0.9474 - val_loss: 0.1043\n",
      "Epoch 36/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0744 - val_accuracy: 0.9474 - val_loss: 0.1035\n",
      "Epoch 37/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.0676 - val_accuracy: 0.9474 - val_loss: 0.1026\n",
      "Epoch 38/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0621 - val_accuracy: 0.9474 - val_loss: 0.1018\n",
      "Epoch 39/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0681 - val_accuracy: 0.9474 - val_loss: 0.1013\n",
      "Epoch 40/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9889 - loss: 0.0565 - val_accuracy: 0.9474 - val_loss: 0.1010\n",
      "Epoch 41/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0733 - val_accuracy: 0.9474 - val_loss: 0.1002\n",
      "Epoch 42/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9788 - loss: 0.0767 - val_accuracy: 0.9474 - val_loss: 0.0992\n",
      "Epoch 43/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0613 - val_accuracy: 0.9474 - val_loss: 0.0985\n",
      "Epoch 44/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.0770 - val_accuracy: 0.9474 - val_loss: 0.0980\n",
      "Epoch 45/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0611 - val_accuracy: 0.9474 - val_loss: 0.0977\n",
      "Epoch 46/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0731 - val_accuracy: 0.9474 - val_loss: 0.0974\n",
      "Epoch 47/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.0687 - val_accuracy: 0.9474 - val_loss: 0.0970\n",
      "Epoch 48/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0633 - val_accuracy: 0.9474 - val_loss: 0.0968\n",
      "Epoch 49/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0667 - val_accuracy: 0.9474 - val_loss: 0.0965\n",
      "Epoch 50/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0475 - val_accuracy: 0.9474 - val_loss: 0.0963\n",
      "Epoch 51/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0432 - val_accuracy: 0.9474 - val_loss: 0.0963\n",
      "Epoch 52/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0530 - val_accuracy: 0.9649 - val_loss: 0.0957\n",
      "Epoch 53/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0688 - val_accuracy: 0.9649 - val_loss: 0.0951\n",
      "Epoch 54/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0556 - val_accuracy: 0.9649 - val_loss: 0.0950\n",
      "Epoch 55/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0650 - val_accuracy: 0.9649 - val_loss: 0.0947\n",
      "Epoch 56/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0484 - val_accuracy: 0.9649 - val_loss: 0.0946\n",
      "Epoch 57/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9883 - loss: 0.0543 - val_accuracy: 0.9649 - val_loss: 0.0947\n",
      "Epoch 58/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0645 - val_accuracy: 0.9649 - val_loss: 0.0943\n",
      "Epoch 59/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0486 - val_accuracy: 0.9649 - val_loss: 0.0942\n",
      "Epoch 60/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9948 - loss: 0.0439 - val_accuracy: 0.9649 - val_loss: 0.0936\n",
      "Epoch 61/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9897 - loss: 0.0585 - val_accuracy: 0.9649 - val_loss: 0.0926\n",
      "Epoch 62/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0542 - val_accuracy: 0.9649 - val_loss: 0.0928\n",
      "Epoch 63/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9947 - loss: 0.0411 - val_accuracy: 0.9649 - val_loss: 0.0931\n",
      "Epoch 64/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.0435 - val_accuracy: 0.9649 - val_loss: 0.0933\n",
      "Epoch 65/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0476 - val_accuracy: 0.9649 - val_loss: 0.0933\n",
      "Epoch 66/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0471 - val_accuracy: 0.9649 - val_loss: 0.0932\n",
      "Epoch 67/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0431 - val_accuracy: 0.9649 - val_loss: 0.0933\n",
      "Epoch 68/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0729 - val_accuracy: 0.9649 - val_loss: 0.0935\n",
      "Epoch 69/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0468 - val_accuracy: 0.9649 - val_loss: 0.0937\n",
      "Epoch 70/70\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9960 - loss: 0.0347 - val_accuracy: 0.9649 - val_loss: 0.0937\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0248 \n",
      "Test loss: 0.022219015285372734\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Build the feedforward neural network\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(16, input_shape=(X_train_scaled.shape[1],), activation='relu'),  # hidden layer with 16 neurons\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # output layer with Sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model for the optimal 70 epochs with validation data\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=70,\n",
    "    validation_data=(X_val_scaled, y_val)\n",
    ")\n",
    "\n",
    "# Optionally, you can also evaluate the model on the test set after training\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3475273-a7fd-4c0a-97c6-95b48a9de9b3",
   "metadata": {},
   "source": [
    "## Part (j)\n",
    "#### Evaluate your final model on the test set using the model.evaluate() function. Report the accuracy on the test set and reflect on how well your model generalizes to unseen data.ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0317172d-1922-4341-aea8-708838e0308c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0248  \n",
      "Test loss 0.0222\n",
      "Test accuracy 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Test loss {:.4f}\".format(test_loss))\n",
    "print(\"Test accuracy {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2368c4",
   "metadata": {},
   "source": [
    "### My test accuracy is 1, which is extremely good because there is no misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1aff99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
